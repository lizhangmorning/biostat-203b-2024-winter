---
title: "Machine Learning Workflow: Logistic regression (MIMIC-IV Data)"
subtitle: "Biostat 203B"
author: "Li Zhang @ UCLA UID:206305918"
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

## Setup

Display system information for reproducibility.

```{r}
sessionInfo()
```


The goal is to predict whether a patient’s ICU stay will be longer than 2 days. You should use the `los_long` variable as the outcome. 

## MIMIC-IV Cohort
```{r} 
library(GGally)
library(gtsummary)
library(tidyverse)
library(tidymodels)
library(dplyr)
library(rsample)

mimiciv_icu_cohort <- readRDS("/Users/zhangli/203b_hw_new/hw4/mimiciv_shiny/mimic_icu_cohort.rds")|>
  arrange(subject_id, hadm_id, stay_id)

# Numerical summaries stratified by the outcome `los_long`.
mimiciv_icu_cohort <- mimiciv_icu_cohort %>%
  select(
    -subject_id, -hadm_id, -stay_id, -los, -dod,
    -intime, -outtime, -admittime, -last_careunit,
    -dischtime, -deathtime, -admit_provider_id,
    -edregtime, -edouttime, -anchor_age,
    -anchor_year, -anchor_year_group,
    -discharge_location, -hospital_expire_flag
  ) %>%
mutate(los_long = as.factor(los_long))

tbl_summary(mimiciv_icu_cohort, by = los_long)

```

- We have following features available at an ICU stay’s `intime`: 

    - Numerical features: `intimeage`, `Bicarbonate`, `Glucose`, `Sodium`, `Chloride`, `Hematocrit`, `Potassium`, `White Blood Cells`, `Creatinine`, `Respiratory Rate`, `Non Invasive Blood Pressure diastolic`, `Heart Rate`, `Non Invasive Blood Pressure systolic`, `Temperature Fahrenheit`.

    - Categorical features coded as string:  `first_careunit`, `admission_type`, `admission_location`, `insurance`, `language`, `marital_status`, `race`, `gender`



## Initial split into test and non-test sets
```{r}
set.seed(203)
data_split <- initial_split(
  mimiciv_icu_cohort, 
  # stratify by los_long
  strata = "los_long", 
  prop = 0.5
  )
data_split

mimic_other <- training(data_split)
dim(mimic_other)
mimic_test <- testing(data_split)
dim(mimic_test)
```

## Recipe
```{r}
logit_recipe <- 
  recipe(
    los_long ~ ., 
    data = mimic_other
  ) |>

  step_impute_mean(Bicarbonate) |>
  step_impute_mean(Glucose) |>
  step_impute_mean(Sodium) |>
  step_impute_mean(Chloride) |>
  step_impute_mean(Hematocrit) |>
  step_impute_mean(Potassium) |>
  step_impute_mean('White Blood Cells') |>
  step_impute_mean(Creatinine) |>
  step_impute_mean('Respiratory Rate') |>
  step_impute_mean('Non Invasive Blood Pressure diastolic') |>
  step_impute_mean('Heart Rate') |>
  step_impute_mean('Non Invasive Blood Pressure systolic') |>
  step_impute_mean('Temperature Fahrenheit') |>


  step_impute_mode(marital_status) |>
  step_impute_mode(first_careunit) |>
  step_impute_mode(admission_type) |>
  step_impute_mode(admission_location) |>
  step_impute_mode(insurance) |>
  step_impute_mode(language) |>
  step_impute_mode(gender) |>
  step_impute_mode(race) |>
  
  # create traditional dummy variables
  step_dummy(all_nominal_predictors()) |>
  # zero-variance filter
  step_zv(all_numeric_predictors()) |> 
  # center and scale numeric data
  step_normalize(all_numeric_predictors()) |>
  # estimate the means and standard deviations
  # prep(training = Heart_other, retain = TRUE) |>
  print()
```

## Model

```{r}
logit_mod <- 
  logistic_reg(
    penalty = tune(), 
    mixture = tune()
  ) |> 
  set_engine("glmnet", standardize = FALSE) |>
  print()
```

## Workflow

Here we bundle the recipe and model.

```{r}
logit_wf <- workflow() |>
  add_recipe(logit_recipe) |>
  add_model(logit_mod) |>
  print()
```

## Tuning grid

Here we tune the `penalty` and `mixture` hyperparameters.

```{r}
param_grid <- grid_regular(
  penalty(range = c(-6, 3)), 
  mixture(),
  levels = c(100, 5)
  ) |>
  print()
```

## Cross-validation (CV)

Set cross-validation partitions.
```{r}
set.seed(203)
# mimic_other$los_long <- factor(mimic_other$los_long)
folds <- vfold_cv(mimic_other, v = 5)
folds
```

Fit cross-validation.
```{r}
(logit_fit <- logit_wf |>
  tune_grid(
    resamples = folds,
    grid = param_grid,
    metrics = metric_set(roc_auc, accuracy),
    # predictors = -los_long
    )) |>
  system.time()
logit_fit
```

Visualize CV results:
```{r}
logit_fit |>
  # aggregate metrics from K folds
  collect_metrics() |>
  print(width = Inf) |>
  filter(.metric == "roc_auc") |>
  ggplot(mapping = aes(x = penalty, y = mean, color = factor(mixture))) +
  geom_point() +
  labs(x = "Penalty", y = "CV AUC") +
  scale_x_log10()
```

Show the top 5 models.
```{r}
logit_fit |>
  show_best("roc_auc")
```
Let's select the best model.
```{r}
best_logit <- logit_fit |>
  select_best("roc_auc")
best_logit
```


## Finalize our model

Now we are done tuning. Finally, let’s fit this final model to the whole training data and use our test data to estimate the model performance we expect to see with new data.

```{r}
# Final workflow
final_wf <- logit_wf |>
  finalize_workflow(best_logit)
final_wf
```

```{r}
# Fit the whole training set, then predict the test cases
final_fit <- 
  final_wf |>
  last_fit(data_split)
final_fit
```

```{r}
# Test metrics
final_fit |> 
  collect_metrics()
```