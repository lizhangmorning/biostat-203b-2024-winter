---
title: "Biostat 203B Homework 5"
subtitle: Due Mar 22 @ 11:59PM
author: "Li Zhang 206305918"
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
---

```{r}
sessionInfo()
```

## Predicting ICU duration

Using the ICU cohort `mimiciv_icu_cohort.rds` you built in Homework 4, develop at least three machine learning approaches (logistic regression with enet regularization, random forest, boosting, SVM, MLP, etc) plus a model stacking approach for predicting whether a patient's ICU stay will be longer than 2 days. You should use the `los_long` variable as the outcome. You algorithms can use patient demographic information (gender, age at ICU `intime`, marital status, race), ICU admission information (first care unit), the last lab measurements before the ICU stay, and first vital measurements during ICU stay as features. You are welcome to use any feature engineering techniques you think are appropriate; but make sure to not use features that are not available at an ICU stay's `intime`. For instance, `last_careunit` cannot be used in your algorithms. 

- The goal is to predict whether a patient’s ICU stay will be longer than 2 days. You should use the `los_long` variable as the outcome. 

## MIMIC-IV Cohort
```{r} 
library(GGally)
library(gtsummary)
library(tidyverse)
library(tidymodels)
library(dplyr)
library(rsample)
library(parsnip)
library(tune)
library(stacks)

mimiciv_icu_cohort <- readRDS("../hw4/mimiciv_shiny/mimic_icu_cohort.rds")|>
  arrange(subject_id, hadm_id, stay_id)

# Numerical summaries stratified by the outcome `los_long`.
mimiciv_icu_cohort <- mimiciv_icu_cohort %>%
  select(
    -subject_id, -hadm_id, -stay_id, -los, -dod,
    -intime, -outtime, -admittime, -last_careunit,
    -dischtime, -deathtime, -admit_provider_id,
    -edregtime, -edouttime, -anchor_age,
    -anchor_year, -anchor_year_group,
    -discharge_location, -hospital_expire_flag
  ) %>%
mutate(los_long = as.factor(los_long))

tbl_summary(mimiciv_icu_cohort, by = los_long)
```

- We have following features available at an ICU stay’s `intime`: 

    - Numerical features: `intimeage`, `Bicarbonate`, `Glucose`, `Sodium`, `Chloride`, `Hematocrit`, `Potassium`, `White Blood Cells`, `Creatinine`, `Respiratory Rate`, `Non Invasive Blood Pressure diastolic`, `Heart Rate`, `Non Invasive Blood Pressure systolic`, `Temperature Fahrenheit`.

    - Categorical features coded as string:  `first_careunit`, `admission_type`, `admission_location`, `insurance`, `language`, `marital_status`, `race`, `gender`

## Initial split into test and non-test sets

```{r}
set.seed(203)
data_split <- initial_split(
  mimiciv_icu_cohort, 
  # stratify by los_long
  strata = "los_long", 
  prop = 0.5
  )
data_split

mimic_other <- training(data_split)
dim(mimic_other)
mimic_test <- testing(data_split)
dim(mimic_test)
```

## Recipe

```{r}
mimic_recipe <- 
  recipe(
    los_long ~ ., 
    data = mimic_other
  ) |>

  step_impute_mean(Bicarbonate) |>
  step_impute_mean(Glucose) |>
  step_impute_mean(Sodium) |>
  step_impute_mean(Chloride) |>
  step_impute_mean(Hematocrit) |>
  step_impute_mean(Potassium) |>
  step_impute_mean('White Blood Cells') |>
  step_impute_mean(Creatinine) |>
  step_impute_mean('Respiratory Rate') |>
  step_impute_mean('Non Invasive Blood Pressure diastolic') |>
  step_impute_mean('Heart Rate') |>
  step_impute_mean('Non Invasive Blood Pressure systolic') |>
  step_impute_mean('Temperature Fahrenheit') |>

  step_impute_mode(marital_status) |>
  
  # create traditional dummy variables
  step_dummy(all_nominal_predictors()) |>
  # zero-variance filter
  step_zv(all_numeric_predictors()) |> 
  # center and scale numeric data
  step_normalize(all_numeric_predictors()) |>
  # estimate the means and standard deviations
  # prep(training = Heart_other, retain = TRUE) |>
  print()
```

## Base models

We will use three different model definitions to try to classify the outcome `los_long`: logistic regression, boosting and random forest.

First we set up the cross-validation folds to be shared by all models.

```{r}
set.seed(203)
folds <- vfold_cv(mimic_other, v = 5)
```

::: {.panel-tabset}

### Logistic regression
```{r}
logit_mod <- 
  logistic_reg(
    penalty = tune(), 
    mixture = tune()
  ) |> 
  set_engine("glmnet", standardize = TRUE)
logit_mod
```

### Random forest
```{r}
rf_mod <- 
  rand_forest(
    mode = "classification",
    # Number of predictors randomly sampled in each split
    mtry = tune(),
    # Number of trees in ensemble
    trees = tune()
  ) |>
  set_engine("ranger")
rf_mod
```

### Boosting
```{r}
gb_mod <- 
  boost_tree(
    mode = "classification",
    trees = 1000, 
    tree_depth = tune(),
    learn_rate = tune()
  ) |> 
  set_engine("xgboost")
gb_mod
```

:::

Bundle the recipe (R) and model into workflow.

::: {.panel-tabset}

### Logistic regression

```{r}
logit_wf <- workflow() |>
  add_recipe(mimic_recipe) |>
  add_model(logit_mod)
logit_wf
```

### Random forest

```{r}
rf_wf <- workflow() |>
  add_recipe(mimic_recipe) |>
  add_model(rf_mod)
rf_wf
```

### Boosting

```{r}
gb_wf <- workflow() |>
  add_recipe(mimic_recipe) |>
  add_model(gb_mod)
gb_wf
```

:::

## Tuning grid

::: {.panel-tabset}

### Logistic regression

```{r}
logit_grid <- grid_regular(
  penalty(range = c(-6, 3)), 
  mixture(),
  levels = c(100, 5)
  )

logit_res <- 
  tune_grid(
    object = logit_wf, 
    resamples = folds, 
    grid = logit_grid,
    control = control_stack_grid()
  )
logit_res
```

### Random forest

```{r}
rf_grid <- grid_regular(
  trees(range = c(100L, 500L)), 
  mtry(range = c(1L, 5L)),
  levels = c(5, 5)
  )

rf_res <- 
  tune_grid(
    object = rf_wf, 
    resamples = folds, 
    grid = rf_grid,
    control = control_stack_grid()
  )
rf_res
```

### Boosting

```{r}
param_grid <- grid_regular(
  tree_depth(range = c(1L, 3L)),
  learn_rate(range = c(-3, 2), trans = log10_trans()),
  levels = c(3, 10)
  )
param_grid

gb_res <- 
  tune_grid(
    object = gb_wf, 
    resamples = folds, 
    grid = param_grid,
    control = control_stack_grid()
  )
gb_res
```

:::

## Model stacking

```{r}
mimic_model_st <- 
  # initialize the stack
  stacks() |>
  # add candidate members
  add_candidates(logit_res) |>
  add_candidates(rf_res) |>
  add_candidates(gb_res) |>
  # determine how to combine their predictions
  blend_predictions(
    penalty = 10^(-6:2),
    metrics = c("roc_auc")
    ) |>
  # fit the candidates with nonzero stacking coefficients
  fit_members()
mimic_model_st
```

Plot the result.

```{r}
autoplot(mimic_model_st)
```

To show the relationship more directly:

```{r}
autoplot(mimic_model_st, type = "members")
```

To see the top results:

```{r}
autoplot(mimic_model_st, type = "weights")
```

To identify which model configurations were assigned what stacking coefficients, we can make use of the `collect_parameters()` function:

```{r}
collect_parameters(heart_model_st, "rf_res")
```

## Final classification

```{r}
mimic_pred <- mimic_test %>%
  bind_cols(predict(mimic_model_st, ., type = "prob")) %>%
  print(width = Inf)
```

Computing the ROC AUC for the model:
```{r}
yardstick::roc_auc(
  mimic_pred,
  truth = los_long,
  contains(".pred_No")
  )
```


We can use the members argument to generate predictions from each of the ensemble members.
```{r}
mimic_pred <-
  mimic_test |>
  select(los_long) |>
  bind_cols(
    predict(
      mimic_model_st,
      mimic_test,
      type = "class",
      members = TRUE
      )
    ) |>
  print(width = Inf)
```

```{r}
map(
  colnames(mimic_pred),
  ~mean(mimic_pred$los_long == pull(mimic_pred, .x))
  ) |>
  set_names(colnames(mimic_pred)) |>
  as_tibble() |>
  pivot_longer(c(everything(), -los_long))
```

